# -*- coding: utf-8 -*-
"""MCA_HW2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RzfJd_WwnOtvwbR5e0W2CplEKWNrD2lk
"""

from google.colab import drive

drive.mount('/content/drive')
root_path = 'drive/My Drive/MCA_Assignment2/Dataset/'  #change dir to your project folder

#REFERENCE: https://fairyonice.github.io/implement-the-spectrogram-from-scratch-in-python.html
#REFERENCE: https://github.com/alexanderlerch/pyACA/tree/master/pyACA
import scipy.io.wavfile as wav
import scipy.signal
from scipy.signal import butter, lfilter
import matplotlib.pyplot as plt
import numpy as np
import os
import pandas as pd
import pickle
import math
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix 
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import normalize

def butter_highpass_filter(data, cutoff, fs, order=5):
    """
    High pass filter using butterworth coefficients
    """
    nyq = 0.5 * fs
    normal_cutoff = cutoff / nyq
    b,a = butter(order, normal_cutoff, btype='high', analog=False)
    y = lfilter(b, a, data)
    return y

def get_xns(sample):
    '''
    Compute Fourier coefficients only up to the Nyquist Limit Xn, n=1,...,L/2
    and multiply the absolute value of the Fourier coefficients by 2, 
    to account for the symetry of the Fourier coefficients above the Nyquest Limit. 
    '''
    mag = []
    L = len(sample)
    t = np.array(range(L))
    argument = (2*np.pi*1j*t)/L
    
    for n in range(int(L/2)): # Nyquist Frequency
        #print("doing it for n = "+str(n))
        xn = sum(sample*np.exp(n*argument))/L
        mag.append(abs(xn)*2)
        
    return(mag)

def create_spectrogram(sample,NFFT,noverlap = None):
    '''
          ts: original time series
        NFFT: The number of data points used in each block for the DFT.
          Fs: the number of points sampled per second, so called sample_rate
    noverlap: The number of points of overlap between blocks. The default value is 128. 
    '''
    if noverlap is None:
        noverlap = int(NFFT/2)

    indices = np.array(range(0, len(sample), NFFT-noverlap))
    indices = list(set(indices) - set(indices[indices + NFFT >= len(sample)]))   #remove windows with size < NFFT
    indices.sort()
    
    xns = np.zeros((len(indices), int(NFFT/2)))
    for i in range(len(indices)):
        xns[i] = get_xns(sample[indices[i]:indices[i] + NFFT])  #STFT
        
    specX = xns.T

    # rescale the absolute value of the spectrogram
    spec = 10*np.log10(specX)
    return (indices,spec)

def plot_spectrogram(spec,sample,ks,sample_rate, L, starts, mappable = None):
    total_sec = len(sample)/sample_rate
    plt.figure()
    plt_spec = plt.imshow(spec,origin='lower')

    ## create ylim
    Nyticks = 10
    ks      = np.linspace(0,spec.shape[0],Nyticks)
    ksHz    = [int(ks[i]*sample_rate/Nyticks) for i in range(len(ks))]
    plt.yticks(ks,ksHz)

    ## create xlim
    Nxticks = 10
    ts_spec = np.linspace(0,spec.shape[1],Nxticks)
    time_factor = starts[len(starts)-1]/len(sample)
    ts_spec_sec  = ["{:4.2f}".format(i) for i in np.linspace(0,total_sec * time_factor]/len(sample), Nxticks)]
    plt.xticks(ts_spec,ts_spec_sec)

    plt.ylabel("Frequency (Hz)")
    plt.xlabel("Time (sec)")

    plt.title("Spectrogram L={} Spectrogram.shape={}".format(L,spec.shape))
    plt.colorbar(mappable,use_gridspec=True)
    plt.show()
    return(plt_spec)

"""Training Spectrograms"""

raw_df = pd.DataFrame(columns=['data', 'sampling_rate', 'category'])
i = 0
for number in os.listdir('training'):
    for file in os.listdir('training/'+number):
        print("doing it for file"+str(i))
        rate, samples = wav.read('training/'+number+'/'+file)
        samples = butter_highpass_filter(samples, 20, rate)
        raw_df.loc[i] = [samples, rate, number]
        i+=1

df = pd.DataFrame(columns=['indices', 'sampling_rate', 'Spectrogram', 'category'])
for i in range(len(raw_df)):
    print("doing it for file"+str(i))
    samples = raw_df.loc[i, "data"]
    rate = raw_df.loc[i, "sampling_rate"]
    total_sec = len(samples)/rate
        
    fourier_mag = get_xns(samples)
    
    ks = np.linspace(0,len(fourier_mag),10)
    ksHz = get_Hz(ks, rate, len(samples))
    
    indices, spec = create_spectrogram(samples, NFFT = 256, noverlap = 128)
    
    df.loc[i] = [indices, rate, spec, raw_df.loc[i,"category"]]

pickle.dump(df, open('specs_training.pkl', 'wb'))

"""Add Noise"""

noise = []
for file in os.listdir(root_path+'_background_noise_/'):
    rate, signal = wav.read(root_path+'_background_noise_/'+file)
    noise.append(signal)

raw_df_train_noise = pd.DataFrame(columns=['data', 'sampling_rate', 'category'])
i = 0
for number in os.listdir('training'):
    for file in os.listdir('training/'+number):
        print("doing it for file"+str(i))
        rate, samples = wav.read('training/'+number+'/'+file)
        samples = butter_highpass_filter(samples, 20, rate)
        signal = signal + 0.005*noise[i%6][:len(signal)]
        raw_df_train_noise.loc[i] = [samples, rate, number]
        i+=1

df_train_noise = pd.DataFrame(columns=['indices', 'sampling_rate', 'Spectrogram', 'category'])
for i in range(len(raw_df_train_noise)):
    print("doing it for file"+str(i))
    samples = raw_df_train_noise.loc[i, "data"]
    rate = raw_df_train_noise.loc[i, "sampling_rate"]
    total_sec = len(samples)/rate
        
    fourier_mag = get_xns(samples)
    
    ks = np.linspace(0,len(fourier_mag),10)
    ksHz = get_Hz(ks, rate, len(samples))
    
    indices, spec = create_spectrogram(samples, NFFT = 256, noverlap = 128)
    
    df_train_noise.loc[i] = [indices, rate, spec, raw_df_train_noise.loc[i,"category"]]

pickle.dump(df_train_noise, open('specs_training_noise.pkl', 'wb'))

"""Validation Spectrograms"""

raw_df_val = pd.DataFrame(columns=['data', 'sampling_rate', 'category'])
i = 0
for number in os.listdir('validation'):
    for file in os.listdir('validation/'+number):
        print("doing it for file"+str(i))
        rate, samples = wav.read('validation/'+number+'/'+file)
        samples = butter_highpass_filter(samples, 20, rate)
        raw_df.loc[i] = [samples, rate, number]
        i+=1

df_val = pd.DataFrame(columns=['Indices', 'Sampling Rate', 'Spectrogram', 'Category'])
for i in range(len(raw_df_val)):
    print("doing it for file"+str(i))
    samples = raw_df_val.loc[i, "data"]
    rate = raw_df_val.loc[i, "sampling_rate"]
    total_sec = len(samples)/rate
        
    fourier_mag = get_xns(samples)
    
    ks = np.linspace(0,len(fourier_mag),10)
    ksHz = get_Hz(ks, rate, len(samples))
    
    indices, spec = create_spectrogram(samples, NFFT = 256, noverlap = 128)
    
    df.loc[i] = [indices, rate, spec, raw_df.loc[i,"category"]]

pickle.dump(df_val, open('specs_val.pkl', 'wb'))

train_specs = pickle.load(open('drive/My Drive/MCA_Assignment2/specs_training.pkl','rb'))
train_noise_specs = pickle.load(open('drive/My Drive/MCA_Assignment2/specs_training_noise.pkl','rb'))
val_specs = pickle.load(open('drive/My Drive/MCA_Assignment2/specs_val.pkl','rb'))

train_specs = pd.DataFrame.from_dict(train_specs, orient='index', columns = ['Sampling Rate', 'Indices', 'Spectrogram', 'Category'])
val_specs = pd.DataFrame.from_dict(val_specs, orient='index', columns = ['Sampling Rate', 'Indices', 'Spectrogram', 'Category'])

train_noise_specs = pd.concat([train_specs, train_noise_specs])
train_noise_specs = train_noise_specs.reset_index()

pickle.dump(train_noise_specs, open('drive/My Drive/MCA_Assignment2/specs_training_noise.pkl', 'wb'))

"""Spectral Features
1. Spectral Centroid
"""

def SpectralCentroid(X, f_s):
    """
    X: spectrogram
    f_s: sampling frequency
    """
    den = sum(X)
    den = np.array([den])

    num_freqs = X.shape[0]
    den[den == 0] = 0.1
    centroid = np.dot(np.array(range(0, num_freqs)), X / den)

    # convert from index to Hz
    nyq_freq = f_s / 2
    centroid = (centroid / num_freqs) * nyq_freq

    return (np.squeeze(centroid))

"""2. Spectral Crest Factor"""

def SpectralCrestFactor(X, f_s):
    """
    X: spectrogram
    f_s: sampling frequency
    """
    den = np.sqrt(np.mean(np.square(X), axis = 0))
    den = np.array([den])
    den[den == 0] = 1

    crest_factor = X.max(axis=0)/den

    return (crest_factor)

"""3. Spectral Decrease"""

def SpectralDecrease(X, f_s):
    """
    X: spectrogram
    f_s: sampling frequency
    """
    # compute index vector
    kinv = [1/a for a in range(1, X.shape[0])]
    kinv.insert(0, 1)  #to avoid divide by zero in prev step
    kinv = np.array(kinv)

    den = sum(X)
    den = np.array([den])

    ind = np.array(list(zip(np.where(den == 0)[0], np.where(den == 0)[1])))
    if ind.size:
        den[den == 0] = 1 + X[0, ind[0][1]]  # hack because I am not sure how to sum subarrays

    den -= X[0, :]

    # compute slope

    spec_decrease = np.dot(kinv, (X - X[0, :])/den)

    return (spec_decrease)

"""4. Spectral Flatness"""

def SpectralFlatness(X, f_s):
    """
    X: spectrogram
    f_s: sampling frequency
    """
    den = np.mean(X, axis = 0)
    den[den == 0] = 1

    X = np.log(X + 1e-20)

    flatness = np.power(math.e, np.mean(X, axis = 0)) / den

    return (flatness)

"""5. Spectral Kurtosis"""

def SpectralKurtosis(X, f_s):
    """
    X: spectrogram
    f_s: sampling frequency
    """
    freqs = (np.array(range(0, X.shape[0])) / X.shape[0]) * f_s / 2
    # get spectral centroid and spread (mean and std of dist)
    centroid = SpectralCentroid(X, f_s)  
    spread = SpectralSpread(X, f_s)    

    den = sum(X)
    den[den == 0] = 1
    spread[spread == 0] = 1

    # compute spread
    kurtosis = np.zeros(X.shape[1])
    for n in range(len(kurtosis)):
        np.put(kurtosis, n, np.dot(np.power((freqs - centroid[n]), 4), X[:, n]) / (np.power(spread[n], 4) * den[n] * X.shape[0]))

    return (kurtosis - 3)

"""6. Spectral RollOff"""

def SpectralRolloff(X, f_s, kappa=0.85):
    """
    X: spectrogram
    f_s: sampling frequency
    """
    den = sum(X)
    den = np.array([den])
    X = np.cumsum(X, axis=0) / den

    rolloff = np.argmax(X >= kappa, axis=0)

    # convert from index to Hz
    nyq_f = f_s / 2
    rolloff = rolloff / ((X.shape[0]) * nyq_f)

    return (rolloff)

"""7. Spectral Slope"""

def SpectralSlope(X, f_s):
    """
    X: spectrogram
    f_s: sampling frequency
    """
    # compute mean
    avg = np.mean(X, axis=0)
    avg = np.array([avg])

    # compute index vector
    kavg = np.array(range(X.shape[0])) - (X.shape[0] / 2)

    # compute slope
    X -= avg
    slope = np.dot(kavg, X) / np.dot(kavg, kavg)

    return (slope)

"""8. Spectral Spread"""

def SpectralSpread(X, f_s):
    """
    X: spectrogram
    f_s: sampling frequency
    """
    nyq_f = f_s/2
    # get spectral centroid as index
    centroid = SpectralCentroid(X, f_s) 
    centroid *= (1/nyq_f) * (X.shape[0])

    # X = X**2 removed for consistency with book

    den = sum(X)
    den[den == 0] = 1

    # compute spread
    spread = np.zeros(X.shape[1])
    indices = np.array(range(X.shape[0]))
    for n in range(X.shape[1]):
        np.put(spread, n, np.dot(np.power((indices - centroid[n]), 2), X[:, n]/den[n]))

    spread = np.power(spread, 1/2)

    # convert from index to Hz
    spread /= X.shape[0]
    spread *= nyq_f

    return (spread)

features_train = pd.DataFrame(columns=['Spectral Centroid', 'Spectral Crest Factor', 'Spectral Decrease', 'Spectral Flatness', 
                                      'Spectral Kurtosis', 'Spectral RollOff', 'Spectral Slope', 'Spectral Spread', 'Category'])
for i in range(1,len(train_specs)+1):
  print("file"+str(i))
  spectrogram = train_specs.loc[i, "Spectrogram"]
  rate = train_specs.loc[i, "Sampling Rate"]
  category = train_specs.loc[i, "Category"]
  features_train.loc[i] = [np.nanmean(SpectralCentroid(spectrogram, rate)), np.nanmean(SpectralCrestFactor(spectrogram, rate)), np.nanmean(SpectralDecrease(spectrogram, rate)),
                           np.nanmean(SpectralFlatness(spectrogram, rate)), np.nanmean(SpectralKurtosis(spectrogram, rate)), 
                           np.nanmean(SpectralRolloff(spectrogram, rate)), np.nanmean(SpectralSlope(spectrogram, rate)), np.nanmean(SpectralSpread(spectrogram, rate)), category]

features_train_noise = pd.DataFrame(columns=['Spectral Centroid', 'Spectral Crest Factor', 'Spectral Decrease', 'Spectral Flatness', 
                                       'Spectral Kurtosis', 'Spectral RollOff', 'Spectral Slope', 'Spectral Spread', 'Category'])
for i in range(len(train_noise_specs)):
  print("file"+str(i))
  spectrogram = train_noise_specs.loc[i, "Spectrogram"]
  rate = train_noise_specs.loc[i, "Sampling Rate"]
  category = train_noise_specs.loc[i, "Category"]
  features_train_noise.loc[i] = [np.nanmean(SpectralCentroid(spectrogram, rate)), np.nanmean(SpectralCrestFactor(spectrogram, rate)), np.nanmean(SpectralDecrease(spectrogram, rate)),
                           np.nanmean(SpectralFlatness(spectrogram, rate)), np.nanmean(SpectralKurtosis(spectrogram, rate)), 
                           np.nanmean(SpectralRolloff(spectrogram, rate)), np.nanmean(SpectralSlope(spectrogram, rate)), np.nanmean(SpectralSpread(spectrogram, rate)), category]

features_val = pd.DataFrame(columns=['Spectral Centroid', 'Spectral Crest Factor', 'Spectral Decrease', 'Spectral Flatness', 
                                       'Spectral Kurtosis', 'Spectral RollOff', 'Spectral Slope', 'Spectral Spread', 'Category'])
for i in range(1,len(val_specs)+1):
  print("file"+str(i))
  spectrogram = val_specs.loc[i, "Spectrogram"]
  rate = val_specs.loc[i, "Sampling Rate"]
  category = val_specs.loc[i, "Category"]
  features_val.loc[i] = [np.nanmean(SpectralCentroid(spectrogram, rate)), np.nanmean(SpectralCrestFactor(spectrogram, rate)), np.nanmean(SpectralDecrease(spectrogram, rate)),
                           np.nanmean(SpectralFlatness(spectrogram, rate)), np.nanmean(SpectralKurtosis(spectrogram, rate)), 
                           np.nanmean(SpectralRolloff(spectrogram, rate)), np.nanmean(SpectralSlope(spectrogram, rate)), np.nanmean(SpectralSpread(spectrogram, rate)), category]

#pickle.dump(features_train, open('features_train.pkl', 'wb'))
pickle.dump(features_train_noise, open('drive/My Drive/MCA_Assignment2/features_train_noise.pkl', 'wb'))
pickle.dump(features_val, open('drive/My Drive/MCA_Assignment2/features_val.pkl', 'wb'))

features_train_noise = pickle.load(open('drive/My Drive/MCA_Assignment2/features_train_noise.pkl', 'rb'))
features_val = pickle.load(open('drive/My Drive/MCA_Assignment2/features_val.pkl', 'rb'))

def encode(x, mapping):
  """
  encode categorical data
  x: array
  mapping: a mapping between categories and numbers
  """
  encoded = [float(mapping[i]) for i in x if type(i) == str]
  return encoded

mapping = {'zero': 0, 'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5, 'six': 6, 'seven': 7, 'eight': 8, 'nine': 9}

#features_train['Category']= encode(features_train['Category'], mapping)
features_train_noise['Category'][:9999]= encode(features_train_noise['Category'][:9999], mapping)
#features_val['Category']= encode(features_val['Category'], mapping)

x_train = features_train_noise[features_train_noise.columns[0:-1]]
x_train = x_train.to_numpy('float64')
x_train = np.nan_to_num(x_train)
y_train = features_train_noise[features_train_noise.columns[-1]]
y_train = y_train.to_numpy()

x_val = features_val[features_val.columns[0:-1]]
x_val = x_val.to_numpy('float64')
x_val = np.nan_to_num(x_val)
y_val = features_val[features_val.columns[-1]]
y_val = y_val.to_numpy()

x_train = normalize(x_train, axis=0, norm='max')
x_val = normalize(x_val, axis=0, norm='max')

param_grid = {'C': [10, 100, 1000],  
              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 
              'kernel': ['rbf']}  
  
grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3) 
  
# fitting the model for grid search 
grid.fit(x_train, y_train)

print(grid.best_params_) 
print(grid.best_estimator_)

pickle.dump(grid, open('drive/My Drive/MCA_Assignment2/svm_spectrogram_noise.pkl', 'wb'))

grid = pickle.load(open('drive/My Drive/MCA_Assignment2/svm_spectrogram.pkl', 'rb'))

grid_predictions = grid.predict(x_val)

print(classification_report(y_val, grid_predictions))