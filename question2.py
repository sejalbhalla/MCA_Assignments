# -*- coding: utf-8 -*-
"""MCA_MFCC.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z2beZTwcB8v93FZOGG_XmbgdmKjB5mm4
"""

from google.colab import drive

drive.mount('/content/drive')
root_path = 'drive/My Drive/MCA_Assignment2/Dataset/'  #change dir to your project folder

import numpy as np
import scipy.io.wavfile as wav
from scipy.fftpack import dct
from scipy.signal import hamming
import pandas as pd
from scipy.stats import skew
import os
import pickle
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix 
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import normalize

from sklearn.metrics import accuracy_score
#from google.colab import files

def pre_emphasize(signal, factor=0.095):
  """
  pre-emphasis filter is used to amplify the high frequencies and improve Signal to Noise Ratio
  signal: raw audio signal
  factor: pre_emphasis factor
  """
  emphasized_signal = np.array([signal[i] - factor*signal[i-1] for i in range(1, len(signal))])
  emphasized_signal = np.insert(emphasized_signal, 0, signal[0])

  return emphasized_signal

def make_frames(signal, sampling_rate, frame_size=0.025, frame_overlap=0.015):
  """
  split the signal into short-time frames to calculate fft of these frames
  signal: pre-emphasized signal
  sampling_rate: sampling rate of the signal in Hz
  frame_size: frame size in s (typically 20-40 ms for speech processing)
  frame_overlap: frame overlap between 2 frames in s
  """
  frame_length = int(round(frame_size * sampling_rate))  #seconds to samples
  frame_step = int(round((frame_size - frame_overlap) * sampling_rate))  #seconds to samples
  #signal_length = len(emphasized_signal)

  nf = abs(len(signal) - frame_length)/float(frame_step)
  num_frames = 0
  if int(nf) < 1:
    num_frames = 1  # Make sure that we have at least 1 frame
  else:
    num_frames = int(np.ceil(nf))

  padding = np.zeros((num_frames * frame_step) + frame_length - len(signal))  #padding to be added at the end of the signal
#  padded_signal = np.concatenate((signal, padding), axis = None)
  padded_signal = np.zeros((len(padding)+len(signal)))
  np.put(padded_signal, list(range(len(signal))), signal)   #put original signal in the front
  np.put(padded_signal, list(range(len(signal), len(padded_signal))), padding)  #put padding at the back after signal

  indices = np.tile(np.array(range(0, frame_length)), (num_frames, 1)) + np.tile(np.array(range(0, num_frames * frame_step, frame_step)), (frame_length, 1)).T
  frames = padded_signal[indices.astype(np.int32, copy=False)]

  #Windowing
  frames = frames * hamming(frame_length)
  return frames

def Hz_to_Mel(x):
  mel = (2595 * np.log10(1 + x / 700))
  return mel

def Mel_to_Hz(x):
  hz = (700 * (np.power(10, (x / 2595)) - 1))
  return hz

def make_filter_banks(power_frames, sampling_rate, NFFT, num_filt = 40):
  """
  computing filter banks is applying triangular filters, typically 40 filters, on a Mel-scale to the power spectrum to extract frequency bands.
  power_frames: power spectrum
  sampling_rate: sampling rate of the signal
  NFFT: Number of points used to calculate FFT for power spectrum
  num_filt: number of triangle filters
  """
  low_freq_mel = 0
  high_freq_mel = Hz_to_Mel(sampling_rate/2)  # Convert Hz to Mel
  #mel_points = np.arange(low_freq_mel, high_freq_mel, (high_freq_mel - low_freq_mel)/(num_filt + 2))  # Equally spaced in Mel scale
  mel_points = np.linspace(low_freq_mel, high_freq_mel, num_filt + 2)  # Equally spaced in Mel scale
  #hz_points = Mel_to_Hz(mel_points)  # Convert Mel to Hz
  bins = np.floor((NFFT + 1) * Mel_to_Hz(mel_points) / sampling_rate)
  
  #bank = np.empty((num_filt, int(np.floor(NFFT / 2 + 1))))
  bank = np.zeros((num_filt, int(np.floor(NFFT / 2 + 1))))
  for m in range(1, num_filt + 1):
      f_s = bins[m - 1 : m + 2]
      f_prev = int(f_s[0])   # left
      f = int(f_s[1])        # center
      f_next = int(f_s[2])   # right

      np.put(bank[m - 1], list(range(f_prev)), 0)                      # k < f_prev

      for k in range(f_prev, f):
          np.put(bank, ((m - 1)*int(np.floor(NFFT / 2 + 1))) + k, (k - f_prev) / (f - f_prev))         
 
      for k in range(f, f_next):
          np.put(bank, ((m - 1)*int(np.floor(NFFT / 2 + 1))) + k, (f_next - k) / (f_next - f))

      np.put(bank[m - 1], list(range(f_next, len(bank))), 0)           # k > f_next

  filter_banks = np.where(np.dot(power_frames, bank.T) == 0, np.finfo(float).eps, np.dot(power_frames, bank.T))
  #filter_banks = np.where(filter_banks == 0, np.finfo(float).eps, filter_banks)  # Numerical Stability
  filter_banks = 20 * np.log10(filter_banks)  # dB

  return filter_banks

def mfcc(signal, sampling_rate, factor=0.095, frame_size=0.025, frame_overlap=0.015, NFFT=512, num_filt = 40):
  """
  calculate MFCC of a signal using helper functions
  signal: raw audio signal
  sampling_rate: sampling rate of the signal
  """
  pre_emphasized = pre_emphasize(signal)
  frames = make_frames(pre_emphasized, rate)

  #FFT and Power Spectrum
  #NFFT = 512
  mag_frames = np.absolute(np.fft.rfft(frames, NFFT))  # Magnitude of the FFT
  power_frames = ((1.0 / NFFT) * (np.power(mag_frames,2)))  # Power Spectrum

  filter_banks = make_filter_banks(power_frames, rate, NFFT)

  #MFCC
  num_ceps = 20
  mfcc_40 = dct(filter_banks, type=2, axis=1, norm='ortho') 
  mfcc = mfcc_40     #[:, 1 : (num_ceps + 1)]   # Keep 2-13

  #Mean Normalization
  mfcc = mfcc - (np.mean(mfcc, axis=0) + 1e-6)

  mfcc_features = np.hstack((np.mean(mfcc.T, axis=1), np.std(mfcc.T, axis=1), skew(mfcc.T, axis = 1), 
                          np.max(mfcc.T, axis = 1), np.median(mfcc.T, axis = 1), np.min(mfcc.T, axis = 1)))
  
  return mfcc_features

"""Setting up the DataFrame Skeleton"""

num_MFCCs = 40
feats = ['Mean', 'Std_Deviation', 'Skew', 'Max', 'Median', 'Min']

cols = []
for j in feats:
    for i in range(1,num_MFCCs+1):
        cols.append('MFCC'+str(i)+"_"+j)

"""Training MFCC Features"""

features_train = pd.DataFrame(columns = cols)
i = 0
category_train = []
for number in os.listdir('training'):
    for file in os.listdir('training/'+number):
        print("file"+str(i))
        rate, signal = wav.read('training/'+number+'/'+file)
        features_train.loc[i] = mfcc(signal, rate)
        category_train.append(number)
        i+=1
features_train['Category'] = category_train

"""Add Noise to Data Files
1. Extract Noise Files
"""

noise = []
for file in os.listdir('_background_noise_/'):
    rate, signal = wav.read('_background_noise_/'+file)
    noise.append(signal)

"""2. Add noise to the signal and calculate MFCC for the noisy signal"""

features_train_noise = pd.DataFrame(columns = cols)
i = 0
category_train_noise = []
for number in os.listdir('training'):
    for file in os.listdir('training/'+number):
        print("file"+str(i))
        rate, signal = wav.read('training/'+number+'/'+file)
        signal = signal + 0.01*noise[i%6][:len(signal)]   #add noise
        features_train_noise.loc[i] = mfcc(signal, rate)
        category_train_noise.append(number)
        i+=1
features_train_noise['Category'] = category_train_noise

"""Validation MFCC Features"""

features_val = pd.DataFrame(columns = cols)
i = 0
category_val = []
for number in os.listdir('validation'):
    for file in os.listdir('validation/'+number):
        print("file"+str(i))
        rate, signal = wav.read('validation/'+number+'/'+file)
        features_val.loc[i] = mfcc(signal, rate)
        category_val.append(number)
        i+=1

features_val['Category'] = category_val

features_train_noise

pickle.dump(features_train, open('mfcc_train.pkl', 'wb'))
#pickle.dump(features_train_noise, open('mfcc_train_noise.pkl', 'wb'))
pickle.dump(features_val, open('mfcc_val.pkl', 'wb'))

features_train = pickle.load(open('drive/My Drive/MCA_Assignment2/mfcc_train.pkl', 'rb'))
features_val = pickle.load(open('drive/My Drive/MCA_Assignment2/mfcc_val.pkl', 'rb'))
features_train_noise = pickle.load(open('drive/My Drive/MCA_Assignment2/mfcc_train_noise.pkl', 'rb'))

features_train_noise = pd.concat([features_train, features_train_noise])
features_train_noise = features_train_noise.reset_index()

features_train_noise = features_train_noise.drop(['index'], axis = 1)

"""Transforming Categorical data to Numerical Values"""

label_encoder = LabelEncoder() 
features_train['Category']= label_encoder.fit_transform(features_train['Category'])
features_val['Category']= label_encoder.fit_transform(features_val['Category'])
features_train_noise['Category'][10000:] = label_encoder.fit_transform(features_train_noise['Category'][10000:])

"""Remove NaN and Inf values to make final x_train and y_train"""

x_train = features_train[features_train.columns[40:-1]] #make it 12 for features_train
x_train = x_train.to_numpy('float64')
x_train = np.nan_to_num(x_train)
y_train = features_train[features_train.columns[-1]]
y_train = y_train.to_numpy()

x_val = features_val[features_val.columns[40:-1]]
x_val = x_val.to_numpy('float64')
x_val = np.nan_to_num(x_val)
y_val = features_val[features_val.columns[-1]]
y_val = y_val.to_numpy()

x_train = normalize(x_train, axis=0, norm='max')
x_val = normalize(x_val, axis=0, norm='max')

"""Fit the SVM"""

param_grid = {'C': [1, 10, 100],  
              'gamma': [0.001, 0.0001, 0.00001, 0.000001], 
              'kernel': ['rbf']}  
  
grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3) 
  
# fitting the model for grid search 
grid.fit(x_train, y_train)

pickle.dump(grid, open('svm_mfcc.pkl', 'wb'))
#files.download('svm_mfcc.pkl')

grid2 = pickle.load(open('mfcc_SVM_weights.pkl', 'rb'))

print(grid.best_params_) 
print(grid.best_estimator_)

grid_predictions = grid.predict(x_val)

print(classification_report(y_val, grid_predictions))